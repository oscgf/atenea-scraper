name: Run Web Scraper

on:
    schedule:
        # Schedule the script to run at 08:00 UTC every day
        - cron: "0 8 * * *"
    # This enables manual triggering
    workflow_dispatch:

jobs:
  scrape_job_offers:
    runs-on: ubuntu-latest

    steps:
    # Checkout the repository
    - name: Checkout Code
      uses: actions/checkout@v3

    # Set up Python
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.12"  # Use the Python version you're working with

    # Install dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    # Configure Git
    - name: Configure Git
      run: |
        git config --global user.email "oscargonzalezfresno@gmail.com"
        git config --global user.name "Óscar González Fresno"
    
    # Run the scraper script
    - name: Run scraper
      run: python your_script.py  # Replace with your script name
    
    # Commit and push changes
    - name: Commit and push changes
      run: |
        git add job_offers.csv
        git commit -m "Update job offers with new data"
        git push https://x-access-token:${{ secrets.GH_PAT }}@github.com/oscgf/ateneo-scraper.git HEAD:main